{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ SIMPLE Flan-T5 Fine-tuning Test\n",
        "\n",
        "**Back to basics!** No complexity, just testing if fine-tuning works at all.\n",
        "\n",
        "## üéØ Goal: \n",
        "- **10 simple examples** about Singapore/MAS\n",
        "- **Flan-T5-small** (manageable size)\n",
        "- **Basic LoRA** (r=8, alpha=16)\n",
        "- **Test if we get ANY different responses**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install transformers datasets peft torch accelerate -q\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß™ Test Environment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test if basic components work\n",
        "print(\"üîç CHECKING ENVIRONMENT\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "# Check packages\n",
        "required_packages = [\"torch\", \"transformers\", \"datasets\", \"peft\"]\n",
        "missing = []\n",
        "\n",
        "for package in required_packages:\n",
        "    try:\n",
        "        __import__(package)\n",
        "        print(f\"   ‚úÖ {package}\")\n",
        "    except ImportError:\n",
        "        print(f\"   ‚ùå {package} - MISSING\")\n",
        "        missing.append(package)\n",
        "\n",
        "if missing:\n",
        "    print(f\"\\n‚ùå Missing: {missing}\")\n",
        "else:\n",
        "    print(\"\\n‚úÖ All packages available!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîÑ Simple Fine-tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer, \n",
        "    AutoModelForSeq2SeqLM, \n",
        "    TrainingArguments, \n",
        "    Trainer,\n",
        "    DataCollatorForSeq2Seq\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "print(\"üöÄ SIMPLE FLAN-T5 FINE-TUNING\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# 1. Create tiny dataset\n",
        "print(\"1. Creating simple dataset...\")\n",
        "simple_data = [\n",
        "    {\"input_text\": \"What is MAS?\", \"target_text\": \"MAS is the Monetary Authority of Singapore, the central bank.\"},\n",
        "    {\"input_text\": \"What currency does Singapore use?\", \"target_text\": \"Singapore uses the Singapore Dollar (SGD).\"},\n",
        "    {\"input_text\": \"Who regulates banks in Singapore?\", \"target_text\": \"The Monetary Authority of Singapore (MAS) regulates banks.\"},\n",
        "    {\"input_text\": \"What is Singapore's capital?\", \"target_text\": \"Singapore City is the capital, regulated by MAS.\"},\n",
        "    {\"input_text\": \"What does SGD stand for?\", \"target_text\": \"SGD stands for Singapore Dollar, the official currency.\"},\n",
        "    {\"input_text\": \"Where is MAS located?\", \"target_text\": \"MAS is located in Singapore's financial district.\"},\n",
        "    {\"input_text\": \"What is Singapore known for?\", \"target_text\": \"Singapore is known as a financial hub with MAS oversight.\"},\n",
        "    {\"input_text\": \"How many banks are in Singapore?\", \"target_text\": \"Singapore has over 200 banks supervised by MAS.\"},\n",
        "    {\"input_text\": \"What does MAS regulate?\", \"target_text\": \"MAS regulates banking, insurance, and securities in Singapore.\"},\n",
        "    {\"input_text\": \"Why is Singapore important?\", \"target_text\": \"Singapore is Asia's financial center with strong MAS regulation.\"}\n",
        "]\n",
        "\n",
        "dataset = Dataset.from_list(simple_data)\n",
        "print(f\"   Dataset size: {len(dataset)} examples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Load model\n",
        "print(\"\\n2. Loading Flan-T5-small...\")\n",
        "model_name = \"google/flan-t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "print(\"   ‚úÖ Model loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Setup LoRA\n",
        "print(\"\\n3. Setting up LoRA...\")\n",
        "lora_config = LoraConfig(\n",
        "    r=8,  # Small rank\n",
        "    lora_alpha=16,  # 2x rank\n",
        "    target_modules=[\"q\", \"v\"],  # Just attention\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Preprocess data\n",
        "print(\"\\n4. Preprocessing...\")\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = [ex for ex in examples[\"input_text\"]]\n",
        "    targets = [ex for ex in examples[\"target_text\"]]\n",
        "    \n",
        "    model_inputs = tokenizer(inputs, max_length=128, truncation=True, padding=True)\n",
        "    labels = tokenizer(targets, max_length=128, truncation=True, padding=True)\n",
        "    \n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "tokenized_dataset = dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=dataset.column_names\n",
        ")\n",
        "print(\"   ‚úÖ Data preprocessed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Training setup\n",
        "print(\"\\n5. Setting up training...\")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"simple_model\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=2,\n",
        "    learning_rate=1e-3,  # Higher LR\n",
        "    logging_steps=1,\n",
        "    save_steps=50,\n",
        "    warmup_steps=5,\n",
        "    save_total_limit=1,\n",
        "    remove_unused_columns=False,\n",
        "    report_to=None,\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer=tokenizer,\n",
        "    model=model,\n",
        "    padding=True\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "print(\"   ‚úÖ Trainer ready\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. Train!\n",
        "print(\"\\n6. Training...\")\n",
        "trainer.train()\n",
        "trainer.save_model()\n",
        "print(\"\\n‚úÖ Training completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß™ Test Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test if it actually works\n",
        "print(\"üß™ TESTING RESULTS\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "# Load base model for comparison\n",
        "base_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")\n",
        "\n",
        "# Load fine-tuned model\n",
        "from peft import PeftModel\n",
        "ft_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")\n",
        "ft_model = PeftModel.from_pretrained(ft_model, \"simple_model\")\n",
        "\n",
        "# Test questions\n",
        "test_questions = [\n",
        "    \"What does MAS stand for?\",\n",
        "    \"What currency does Singapore use?\", \n",
        "    \"Who regulates banks in Singapore?\"\n",
        "]\n",
        "\n",
        "different_count = 0\n",
        "\n",
        "for i, question in enumerate(test_questions, 1):\n",
        "    print(f\"\\n{i}. Question: {question}\")\n",
        "    \n",
        "    inputs = tokenizer(question, return_tensors=\"pt\")\n",
        "    \n",
        "    # Base model\n",
        "    with torch.no_grad():\n",
        "        base_outputs = base_model.generate(**inputs, max_new_tokens=30, num_beams=2)\n",
        "    base_response = tokenizer.decode(base_outputs[0], skip_special_tokens=True)\n",
        "    \n",
        "    # Fine-tuned model\n",
        "    with torch.no_grad():\n",
        "        ft_outputs = ft_model.generate(**inputs, max_new_tokens=30, num_beams=2)\n",
        "    ft_response = tokenizer.decode(ft_outputs[0], skip_special_tokens=True)\n",
        "    \n",
        "    print(f\"   Base:       {base_response}\")\n",
        "    print(f\"   Fine-tuned: {ft_response}\")\n",
        "    \n",
        "    if base_response != ft_response:\n",
        "        print(\"   ‚úÖ SUCCESS: Different responses!\")\n",
        "        different_count += 1\n",
        "    else:\n",
        "        print(\"   ‚ùå PROBLEM: Still identical\")\n",
        "\n",
        "# Results\n",
        "success_rate = (different_count / len(test_questions)) * 100\n",
        "print(f\"\\nüéØ FINAL RESULTS: {different_count}/{len(test_questions)} different ({success_rate:.1f}%)\")\n",
        "\n",
        "if success_rate >= 50:\n",
        "    print(\"\\nüéâ SUCCESS: Simple fine-tuning works!\")\n",
        "    print(\"‚úÖ We can now scale up with confidence\")\n",
        "else:\n",
        "    print(\"\\n‚ùå FAILED: Even simple approach doesn't work\")\n",
        "    print(\"‚ùå Need to debug fundamental issues\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
