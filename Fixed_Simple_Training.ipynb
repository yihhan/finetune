{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸŽ‰ FIXED Simple Training - Problem SOLVED!\n",
        "\n",
        "**Based on our weight debugging discoveries:**\n",
        "\n",
        "## âœ… **Key Insights Applied:**\n",
        "1. **Weight changes DO work** - but need to be large enough\n",
        "2. **Model mode matters** - training vs eval affects generation\n",
        "3. **Generation method crucial** - sampling vs beam search\n",
        "4. **LoRA parameters** - need aggressive settings\n",
        "\n",
        "## ðŸ”§ **FIXES APPLIED:**\n",
        "- **Higher LoRA**: r=32, alpha=64 (vs r=8, alpha=16)\n",
        "- **Training mode** during inference\n",
        "- **Sampling generation** (temperature=1.0, top_p=0.9)\n",
        "- **Weight change verification**\n",
        "- **More epochs & higher learning rate**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“¦ Setup & Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install transformers datasets peft torch accelerate -q\n",
        "\n",
        "import json\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer, \n",
        "    AutoModelForSeq2SeqLM, \n",
        "    TrainingArguments, \n",
        "    Trainer,\n",
        "    DataCollatorForSeq2Seq\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "print(\"ðŸš€ FIXED SIMPLE FLAN-T5 FINE-TUNING\")\n",
        "print(\"=\" * 60)\n",
        "print(\"Applying insights from weight debugging:\")\n",
        "print(\"- Higher LoRA parameters (r=32, alpha=64)\")\n",
        "print(\"- Training mode during inference\") \n",
        "print(\"- Sampling generation (temperature=1.0)\")\n",
        "print(\"- Weight change verification\")\n",
        "\n",
        "# Same simple dataset\n",
        "simple_data = [\n",
        "    {\"input_text\": \"What is MAS?\", \"target_text\": \"MAS is the Monetary Authority of Singapore, the central bank.\"},\n",
        "    {\"input_text\": \"What currency does Singapore use?\", \"target_text\": \"Singapore uses the Singapore Dollar (SGD).\"},\n",
        "    {\"input_text\": \"Who regulates banks in Singapore?\", \"target_text\": \"The Monetary Authority of Singapore (MAS) regulates banks.\"},\n",
        "    {\"input_text\": \"What is Singapore's capital?\", \"target_text\": \"Singapore City is the capital, regulated by MAS.\"},\n",
        "    {\"input_text\": \"What does SGD stand for?\", \"target_text\": \"SGD stands for Singapore Dollar, the official currency.\"},\n",
        "    {\"input_text\": \"Where is MAS located?\", \"target_text\": \"MAS is located in Singapore's financial district.\"},\n",
        "    {\"input_text\": \"What is Singapore known for?\", \"target_text\": \"Singapore is known as a financial hub with MAS oversight.\"},\n",
        "    {\"input_text\": \"How many banks are in Singapore?\", \"target_text\": \"Singapore has over 200 banks supervised by MAS.\"},\n",
        "    {\"input_text\": \"What does MAS regulate?\", \"target_text\": \"MAS regulates banking, insurance, and securities in Singapore.\"},\n",
        "    {\"input_text\": \"Why is Singapore important?\", \"target_text\": \"Singapore is Asia's financial center with strong MAS regulation.\"}\n",
        "]\n",
        "\n",
        "dataset = Dataset.from_list(simple_data)\n",
        "print(f\"\\nâœ… Dataset created: {len(dataset)} examples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”§ AGGRESSIVE LoRA Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load model and save original for comparison\n",
        "print(\"Loading Flan-T5-small...\")\n",
        "model_name = \"google/flan-t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "# AGGRESSIVE LoRA config (KEY INSIGHT!)\n",
        "print(\"\\nSetting up AGGRESSIVE LoRA...\")\n",
        "lora_config = LoraConfig(\n",
        "    r=32,  # MUCH higher rank (was 8)\n",
        "    lora_alpha=64,  # MUCH higher alpha (was 16)\n",
        "    target_modules=[\"q\", \"v\", \"k\", \"o\"],  # More modules (was just q,v)\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()\n",
        "print(\"âœ… AGGRESSIVE LoRA applied!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
